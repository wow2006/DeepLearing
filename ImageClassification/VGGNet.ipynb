{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from json import load\n",
    "from tflearn.layers.core import input_data\n",
    "\n",
    "with open(\"VGG.json\", \"r\") as inputFile:\n",
    "    layers = load(inputFile)\n",
    "networkRoot = layers['VGG']['VGG11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.core import input_data, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.misc import imresize\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "\n",
    "# Bug at resize_pics don't work\n",
    "X_, Y = oxflower17.load_data(dirname='Data/17flowers', one_hot=True,\n",
    "                            resize_pics=(224, 224))\n",
    "\n",
    "X = np.empty((X_.shape[0], 224, 224, 3), dtype=np.float32)\n",
    "for i, image in enumerate(X_):\n",
    "    # return is RGB 224x224 and float64 [0-255]\n",
    "    temp = imresize(image, (224, 224), mode='RGB').astype(np.float32)\n",
    "    X[i] = temp / np.max(temp)\n",
    "X_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "\n",
    "# Real-time data preprocessing\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Real-time data augmentation\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Utility import createArchitecture\n",
    "# VGGNet Config A (11 weight layers)\n",
    "network = input_data(shape=[None, 224, 224, 3],\n",
    "                     data_preprocessing=img_prep,\n",
    "                     data_augmentation=img_aug)\n",
    "network = createArchitecture(networkRoot, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = fully_connected(network, 17, activation='softmax')\n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![VGGNet](Data/VGGNetConfig.png)\n",
    "![VGG](Data/VGG_Tensorboard.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "if os.path.exists('/tmp/tflearn_logs/vgg11_oxflowers17/'):\n",
    "    shutil.rmtree('/tmp/tflearn_logs/vgg11_oxflowers17/')\n",
    "\n",
    "# Training\n",
    "model = tflearn.DNN(network, checkpoint_path='Data/checkpoint/model_vgg11', max_checkpoints=1,\n",
    "                    tensorboard_verbose=2)\n",
    "model.fit(X, Y, n_epoch=500, shuffle=True,\n",
    "          show_metric=True, batch_size=1, snapshot_step=500,\n",
    "          snapshot_epoch=False, run_id='vgg11_oxflowers17')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
